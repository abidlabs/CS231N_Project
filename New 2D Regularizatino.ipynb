{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Extracting data/fashion\\train-images-idx3-ubyte.gz\n",
      "Extracting data/fashion\\train-labels-idx1-ubyte.gz\n",
      "Extracting data/fashion\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "\n",
    "import numpy as np, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "params = {\n",
    "   'axes.labelsize': 16,\n",
    "   'font.size': 16,\n",
    "   'legend.fontsize': 16,\n",
    "   'xtick.labelsize': 13,\n",
    "   'ytick.labelsize': 13,\n",
    "   'text.usetex': False,\n",
    "    'font.family':\"sans-serif\",\n",
    "   'font.sans-serif':'Arial',\n",
    "   'text.usetex': False,\n",
    "   }\n",
    "\n",
    "#mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist = input_data.read_data_sets(\"data/fashion\", one_hot=True)\n",
    "\n",
    "rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DZ_reg2D(weights,chain=1,discount=0.9,chain_stride=1):\n",
    "    result = 0\n",
    "    for i in np.arange(chain):\n",
    "        weights_rolled_1=tf.manip.roll(weights, shift=[-chain_stride*(i+1),-(i+1)], axis=[0,2])\n",
    "        weights_rolled_2=tf.manip.roll(weights, shift=[-chain_stride*(i+1),-(i+1)], axis=[1,3])\n",
    "        result += tf.reduce_mean(tf.square(weights_rolled_1-weights))*(discount**i)+tf.reduce_mean(tf.square(weights_rolled_2-weights))*(discount**i)        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected2D(pool=4, num_channels=10, verbose=True, return_weights=False, reg_kind=None, reg_value=None, chain=1, discount=0.9,stride=1):\n",
    "    \n",
    "    d = int(784/pool/pool)\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    H_dim = 9\n",
    "    #hidden layer\n",
    "    W_fc1 = get_variable([28,28, H_dim,H_dim,num_channels])\n",
    "    b_fc1 = get_variable([H_dim,H_dim,num_channels])\n",
    "    # W_fc1 = weight_variable([784, 7840])\n",
    "    # b_fc1 = bias_variable([7840])\n",
    "    x_reshaped = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    #x_reshaped = tf.nn.max_pool(x_reshaped, [1, pool, pool,1], [1, pool, pool, 1], padding='SAME')\n",
    "    #x_reshaped = tf.reshape(x_reshaped, [-1, d])\n",
    "    h_fc1 = tf.sigmoid(tf.tensordot(x_reshaped, W_fc1, axes= [[1,2],[0,1]]) + b_fc1)\n",
    "    h_fc1 = tf.reshape(h_fc1,[-1,H_dim*H_dim*num_channels] )\n",
    "    \n",
    "    #output layer\n",
    "    W_fc2 = get_variable([H_dim*H_dim*num_channels, 10])\n",
    "    # W_fc2 = weight_variable([7840, 10])\n",
    "    b_fc2 = get_variable([10])\n",
    "    y = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "    loss = regularize(loss, W_fc1, reg_kind, reg_value, chain, discount,stride)\n",
    "    train_step = tf.train.GradientDescentOptimizer(3.0).minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        for i in range(1000):\n",
    "            batch = mnist.train.next_batch(100)\n",
    "            train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "            if i%100==0:\n",
    "                accuracy_train = accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels})\n",
    "                accuracy_valid = accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "                if verbose:\n",
    "                    print('Train acc:',accuracy_train, 'Valid acc:',accuracy_valid)\n",
    "        \n",
    "        return_values = [accuracy_train, accuracy_valid]\n",
    "        if return_weights:\n",
    "            return_values.append(sess.run(W_fc1))\n",
    "        \n",
    "    return return_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
